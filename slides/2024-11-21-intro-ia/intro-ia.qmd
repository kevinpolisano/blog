---
title: Introduction à l'intelligence artificielle
subtitle: Une brève excursion dans le monde du machine learning 
format: 
  clean-revealjs:
    self-contained: true
    autoplay: true
    #chalkboard: true
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: Kévin Polisano
    email: kevin.polisano@cnrs.fr
    affiliations: CNRS, Laboratoire Jean Kuntzmann
date: last-modified
bibliography: refs.bib
---


```{r}
render_media <- function(version, local_src = NULL, youtube_src = NULL, ratio = 1, margin = 0) {
  if (version == "local") {
    return(knitr::asis_output(paste0(
      '<video onloadstart="this.playbackRate = 2;" data-autoplay src="', local_src,'" controls muted></video>'
    )))
  } else if (version == "online") {
    width <- 896*ratio
    height <- 504*ratio
    return(knitr::asis_output(paste0(
      '<div style="display: flex; justify-content: center; align-items: center; height: auto; margin-bottom: ', margin, 'cm; padding: 0;">',
      '<iframe data-external="1" data-autoplay="1" width="', width,'" height="', height, '" src="', youtube_src, '&amp;autoplay=1&amp;loop=1&amp;controls=0&amp;modestbranding=1&amp;autohide=1"',
      ' title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"',
      ' referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>',
      '</div>'
    )))
  } else {
    return("")
  }
}
```

```{r setup}
# Déclaration de la variable globale version
version <- "online"
version <- "local"
```

# Contexte historique {background-color="#40666e"}

## Panorama de l'intelligence artificielle

### Le machine learning est une branche de l'IA

![](images/ia-vs-machine-learning-vs-deep-learning.jpg){fig-align="center"}

::: footer
Source : [inventiv-it.fr](https://inventiv-it.fr/ai-machine-learning-deep-learning/)
:::

## Carte du Machine Learning (ML) {background-color="black"}

![](images/carte-ia.jpg){fig-align="center" width="80%"}

::: footer
Source : [Machine Learnia](https://www.youtube.com/watch?v=mT6NnslbNLM)
:::

## Qui suis-je ?

### Un esprit visionnaire sur les potentialités des machines

*"Again, it might act upon other things [besides number]{.alert}, were objects found whose mutual fundamental relations could be expressed by those of the abstract science of operations, and which should be also susceptible of adaptations to the action of the operating notation and mechanism of the engine. Supposing, for instance, that [the fundamental relations of pitched sounds]{.alert} in the science of harmony and of musical composition were susceptible of such expression and adaptations, [the engine might compose elaborate and scientific pieces of music]{.alert} of any degree of complexity or extent"*

**A.L.L**

::: footer
Source : [Sketch of the analytical engine](https://www.fourmilab.ch/babbage/sketch.html)
:::

::: notes
Encore une fois, cela pourrait agir sur d'autres éléments en plus des nombres, si l'on trouvait des objets dont les relations fondamentales mutuelles pourraient être exprimées par celles de la science abstraite des opérations, et qui seraient également susceptibles d’adaptations à l’action de la notation et du mécanisme opérant de la machine. En supposant, par exemple, que les relations fondamentales entre les fréquences dans la science de l'harmonie et les règles de la composition musicale soient susceptibles d'une telle expression, la machine pourrait composer des morceaux de musique élaborés et scientifiques, de n'importe quel degré de complexité ou d'étendue.
:::

## Ada Lovelace

### L'enchanteresse des nombres

::::: columns
::: {.column width="50%"}
![](images/ada-lovelace.png){fig-align="center"}
:::

::: {.column width="50%"}
-   [1815]{.alert} - Naissance d'Ada Lovelace à Londres, fille du poète Lord Byron et d'Anne Isabella Milbanke.
-   [1833]{.alert} - Rencontre avec Charles Babbage, mathématicien et inventeur de la machine analytique.
-   [1842-1843]{.alert} - Publication des Notes, ajoutées à la traduction d'un article du mathématicien italien Luigi Menabrea.
-   [1852]{.alert} - Décès à l'âge de 36 ans, des suites d'un cancer.
:::
:::::

::: footer
Source : [Wikipédia](https://en.wikipedia.org/wiki/Ada_Lovelace)
:::

::: notes
un précurseur de l'ordinateur moderne. Cette rencontre marquera le début de sa fascination pour les mathématiques et les machines. Elle y ajoute ses propres notes, qui occupent plus de place que l'article lui-même et dans lesquelles elle propose ce qui est souvent considéré comme le premier algorithme conçu pour une machine, visant à calculer les nombres de Bernoulli. sur la machine analytique de Babbage. - 1843 - Paternité de la Programmation : Ses notes incluent des concepts de boucles et de programmation conditionnelle. Ces idées font d'elle la première personne à conceptualiser un algorithme pour un ordinateur, lui conférant le titre de "première programmeuse".
:::

<!-- 

## {background-iframe="https://danferns.github.io/linear-regression-visualizer/" background-interactive="true"}

-->

## La régression linéaire

### Visualisation de la méthode des moindres carrés

::: {style="text-align: center;"}
<iframe scrolling="no" title="Interactive Linear Regression" src="https://www.geogebra.org/material/iframe/id/xC6zq7Zv/width/800/height/503/border/888888/sfsb/true/smb/false/stb/false/stbh/false/ai/false/asb/false/sri/false/rc/false/ld/false/sdz/false/ctl/false" width="800px" height="503px" style="border:0px;">

</iframe>
:::

::: footer
Source : [Geogebra](https://www.geogebra.org/m/xC6zq7Zv)
:::

## Visualisation de la descente de gradient {background-color="black"}

![](videos/linear-regression-gradient-descent.mp4){loop="true" data-autoplay="true" width="120%"}

## Les 4 principaux ingrédients du ML {background-color="black"}

1.  [Des données]{.fg style="--col: #7abce4"}
2.  [Un modèle]{.fg style="--col: #f4ef52"}
3.  [Une fonction de coût]{.fg style="--col: #d87a76"}
4.  [Un algorithme d'optimisation]{.fg style="--col: #9cbb87"}

```{r, results='asis'}
render_media(version, local_src = "videos/quatre-ingredients.m4v", youtube_src = "https://www.youtube.com/embed/XUFLq6dKQok?si=2wrQuAnmmQL8n2fu&amp;start=129&amp;end=176", ratio = 0.7, margin = -1)
```

## Types d'apprentissages 
### Supervisés, non-supervisés et par ré-enforcement

![](images/machine-learning-types.png){fig-align="center"}

## L'invention des neurones artificiels {background-color="black"}
### 1943 - Warren McCulloch et Walter Pitts

```{r, results='asis'}
render_media(version, local_src = "videos/neurones-biologiques.mp4", youtube_src = "https://www.youtube.com/embed/XUFLq6dKQok?si=uoi7RRMux0DdlKCD&amp;start=358&amp;end=535")
```

::: footer
Source : [Machine Learnia](https://www.youtube.com/watch?v=XUFLq6dKQok)
:::
	
::: notes
Les premiers réseaux de neurones ont donc été inventés en 1943 par deux mathématiciens et neuroscientifiques du nom de Warren McCulloch et Walter Pitts.
Dans leur article scientifique intitulé : "A Logical Calculus of the ideas immanent in nervous activity",
ils expliquent comment ils ont pu programmer des neurones artificiels en s'inspirant du fonctionnement des neurones biologiques.
Rappelons le, en biologie, les neurones sont des cellules excitables connectées les unes aux autres,
et ayant pour rôle de transmettre des informations dans notre système nerveux.
Chaque neurone est composé de plusieurs dendrites, d'un corps cellulaire, et d'un axone.
Les dendrites sont en quelque sorte les portes d'entrée d'un neurone. c'est à cet endroit, au niveau de la synapse, que le neurone reçoit des signaux lui provenant des neurones qui le précèdent.
Ces signaux peuvent être de type excitateur ou à l'inverse inhibiteur. (un peu comme si nous avions des signaux qui valent +1 et d'autres qui valent -1).
Lorsque la somme de ces signaux dépasse un certain seuil, le neurone s'active et produit alors un signal électrique.
Ce signal circule le long de l'axone en direction des terminaisons pour être envoyé à son tour vers d'autres neurones de notre système nerveux...
...neurones qui fonctionneront exactement de la même manière ! Voilà en gros, le fonctionnement des neurones.
Ce que Warren McCulloch et Walter Pitts ont essayé de faire, c'est de modéliser ce fonctionnement,
en considérant qu'un neurone pouvait être représenté par une fonction de transfert, qui prend en entrée des signaux X et qui retourne une sortie y.
A l'intérieur de cette fonction, on trouve 2 grandes étapes.
La première, c'est une étape d'agrégation. On fait la somme de toutes les entrées du neurone,
en multipliant au passage chaque entrée par un coefficient W. ce coefficient représente en fait l'activité synaptique, c'est à dire le fait que le signal soit excitateur auquel cas w vaut +1, ou bien inhibiteur auquel cas il vaut -1.
Dans cette phase d'agrégation, on obtient donc une expression de la forme w1 x1 + w 2 x 2 + w3 x3 etc etc.
Une fois cette étape réalisée, on passe à la phase d'activation. On regarde le résultat du calcul effectué précédemment,
et si celui ci dépasse un certain seuil, en général 0, alors le neurone s'active et retourne une sortie y = 1. Sinon, il reste à 0.
Voilà donc comment Warren McCulloch et Walter Pitts ont réussi à développer les premiers neurones artificiels
:::

## L'invention du Perceptron {background-color="black"}
### 1957 - Frank Rosenblatt

```{r, results='asis'}
render_media(version, local_src = "videos/perceptron.mp4", youtube_src = "https://www.youtube.com/embed/XUFLq6dKQok?si=uoi7RRMux0DdlKCD&amp;start=657&amp;end=834")
```

::: footer
Source : [Machine Learnia](https://www.youtube.com/watch?v=XUFLq6dKQok)
:::
	

## Classification

<video onloadstart="this.playbackRate = 2;" data-autoplay start="20" src="videos/classification-test.mp4" controls muted>
</video>


